{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G1mdbcpZQTHw"
      },
      "outputs": [],
      "source": [
        "#tutorial pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "3nVoUrA6QVNb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "##\n",
        "##1ra parte: tensores\n",
        "##\n",
        "##########################"
      ],
      "metadata": {
        "id": "i1d-XPnMQWwL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cOVszi7QfTI",
        "outputId": "0cf7e3c7-79d8-47d8-d641-e77de2f1f9b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.tensor([[1,2,3],[4,5,6]], dtype = torch.float32, device = device, requires_grad=True)\n",
        "print(my_tensor)\n",
        "print(my_tensor.dtype)\n",
        "print(my_tensor.device)\n",
        "print(my_tensor.shape)\n",
        "print(my_tensor.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_4M6H8dQnOk",
        "outputId": "ccfd5ec8-a6b9-4fa6-d7e0-b106550c5b66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], requires_grad=True)\n",
            "torch.float32\n",
            "cpu\n",
            "torch.Size([2, 3])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#otra forma de iniciar un tensor\n",
        "x = torch.empty(size=(3,3)) #inicia con valores aleatorios\n",
        "print(x)\n",
        "x= torch.zeros(size = (3,3)) #no es necesario el size\n",
        "print(x)\n",
        "x = torch.rand((3,3))\n",
        "print(x)\n",
        "x = torch.ones((3,3))\n",
        "print(x)\n",
        "x = torch.eye(5,5) # matriz identidad, eye es porque suena a I (identity)\n",
        "print(x)\n",
        "x = torch.arange(start=0, end = 5, step = 1)\n",
        "print(x)\n",
        "x = torch.linspace(start = 0.1, end = 1, steps = 10) #parte en 0.1, termina en 1 y tendra 10 valores intermedios (incluiyendo 0.1 y 1)\n",
        "print(x)\n",
        "x = torch.empty(size = (1,5)).normal_(mean=0, std= 1) #al inicio vimos que iniciaba con valores aleatorios, aca le damos una distribuicion, media y desviacion\n",
        "print(x)\n",
        "x = torch.empty(size = (1,5)).uniform_(0,1) #distro uniforme\n",
        "print(x)\n",
        "x = torch.diag((torch.ones(3))) #esencialmente es otra forma de hacer la identidad de 3x3\n",
        "print(x)\n",
        "\n",
        "#iniciar y convertir entre distintos tipos (int, float, double)\n",
        "tensor = torch.arange(4)\n",
        "print(tensor.bool()) #numeros > 0 seran true\n",
        "print(tensor.short()) #int16\n",
        "print(tensor.long()) #int64\n",
        "print(tensor.half()) #float16\n",
        "print(tensor.float()) #float32, uno de los mas usados\n",
        "print(tensor.double()) #float64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuqIldJsRFhM",
        "outputId": "71a1a346-71da-4570-8f5b-ae8219c26546"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.0451e-34, 0.0000e+00, 0.0000e+00],\n",
            "        [2.0000e+00, 0.0000e+00, 2.1250e+00],\n",
            "        [0.0000e+00, 2.2500e+00, 0.0000e+00]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[0.0791, 0.2653, 0.8128],\n",
            "        [0.7762, 0.7146, 0.9603],\n",
            "        [0.7174, 0.1427, 0.4655]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([0, 1, 2, 3, 4])\n",
            "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
            "        1.0000])\n",
            "tensor([[-0.6095, -0.5598,  0.2538,  1.5329,  0.2659]])\n",
            "tensor([[0.4545, 0.5468, 0.3124, 0.8833, 0.7467]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "tensor([False,  True,  True,  True])\n",
            "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convertir de numpy a ternsor\n",
        "import numpy as np\n",
        "np_array = np.zeros((5,5))\n",
        "tensor = torch.from_numpy(np_array)\n",
        "print(tensor)\n",
        "np_array_back = tensor.numpy()\n",
        "print(np_array_back)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JElgnJSk5M",
        "outputId": "6b33ed1c-4dc6-4356-e44e-8c9ad7c02bf1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor maths\n",
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([9,8,7])\n",
        "\n",
        "#suma, hay varias rformas\n",
        "z1 = torch.empty(3)\n",
        "torch.add(x,y,out=z1)\n",
        "print(z1)\n",
        "\n",
        "z2 = torch.add(x,y)\n",
        "print(z2)\n",
        "\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "#resta tambien hay varias, la mas directa\n",
        "z = x-y\n",
        "print(z)\n",
        "\n",
        "#division\n",
        "z = torch.true_divide(x,y) #(1/9,2/8, 3/7)\n",
        "print(z)\n",
        "\n",
        "########################\n",
        "#\n",
        "# operaciones \"inplace\"\n",
        "#\n",
        "#########################\n",
        "t = torch.zeros(3)\n",
        "t.add_(x)\n",
        "print(t)\n",
        "t += x\n",
        "print(t)\n",
        "\n",
        "#exponenciacion\n",
        "z = x.pow(2)\n",
        "print(z)\n",
        "\n",
        "z = x **2\n",
        "print(z)\n",
        "\n",
        "#division\n",
        "z = x.div(y)\n",
        "print(z)\n",
        "\n",
        "#multiplicacion\n",
        "z = x.mul(y)\n",
        "print(z)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfKp42LBU3H-",
        "outputId": "f93f21e6-06a9-4ac8-d6d2-7e1cc76b846a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10., 10., 10.])\n",
            "tensor([10, 10, 10])\n",
            "tensor([10, 10, 10])\n",
            "tensor([-8, -6, -4])\n",
            "tensor([0.1111, 0.2500, 0.4286])\n",
            "tensor([1., 2., 3.])\n",
            "tensor([2., 4., 6.])\n",
            "tensor([1, 4, 9])\n",
            "tensor([1, 4, 9])\n",
            "tensor([0.1111, 0.2500, 0.4286])\n",
            "tensor([ 9, 16, 21])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "#\n",
        "# comparaciones\n",
        "#\n",
        "####################################\n",
        "z = x > 0\n",
        "print(z)\n",
        "z = x < 0\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gPaWRYRXWgV",
        "outputId": "f076e417-5a61-490a-d60b-72da15416d6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True])\n",
            "tensor([False, False, False])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multiplicacion de matrices\n",
        "x1 = torch.rand((2,5))\n",
        "x2 = torch.rand((5,3)) #2x3\n",
        "x3 = torch.mm(x1,x2) #mm matrix multiplication\n",
        "print(x3)\n",
        "x3 = x1.mm(x2)\n",
        "print(x3)\n",
        "\n",
        "#exponenciacion de matrices\n",
        "matrix_exp = torch.rand((5,5))\n",
        "print(matrix_exp)\n",
        "matrix_exp = matrix_exp.matrix_power(3)\n",
        "print(matrix_exp)\n",
        "\n",
        "#multiplicacion elemento a elemento (element wise mult: ((a,b),(c,d)) x ((a',b'),(c',d')) = ((a*a',b*b'),(c*c',d*d'))\n",
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([9,8,7])\n",
        "z = x * y\n",
        "print(z)\n",
        "\n",
        "#producto cruz (dot product)\n",
        "z = torch.dot(x,y)\n",
        "print(z)\n",
        "\n",
        "#multiplicacion de matrices por lotes (batch matrix multipliocation)\n",
        "batch = 32\n",
        "n = 10\n",
        "m = 20\n",
        "p = 30\n",
        "tensor1 =torch.rand((batch, n,m))\n",
        "print(tensor1)\n",
        "tensor2 =torch.rand((batch, m,p))\n",
        "\n",
        "out_bbmm = torch.bmm(tensor1, tensor2)\n",
        "print(out_bbmm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c851vwUgXoSH",
        "outputId": "7331f851-da9f-4eee-85cf-1da9ba56ab39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7587, 1.3107, 0.4490],\n",
            "        [1.0203, 0.6216, 0.3288]])\n",
            "tensor([[1.7587, 1.3107, 0.4490],\n",
            "        [1.0203, 0.6216, 0.3288]])\n",
            "tensor([[0.9701, 0.6094, 0.5127, 0.4896, 0.1436],\n",
            "        [0.6943, 0.9744, 0.6586, 0.9985, 0.0340],\n",
            "        [0.1774, 0.9658, 0.7351, 0.0758, 0.6709],\n",
            "        [0.5973, 0.8901, 0.3886, 0.4905, 0.9395],\n",
            "        [0.6017, 0.0877, 0.4440, 0.5506, 0.5430]])\n",
            "tensor([[5.0163, 6.0437, 4.4896, 4.4203, 3.2824],\n",
            "        [6.4086, 7.7167, 5.7715, 5.8204, 4.2524],\n",
            "        [4.4695, 5.6780, 4.1699, 3.9859, 3.2965],\n",
            "        [5.8403, 6.9611, 5.1656, 5.0059, 4.1570],\n",
            "        [3.8363, 4.3131, 3.4004, 3.3224, 2.5931]])\n",
            "tensor([ 9, 16, 21])\n",
            "tensor(46)\n",
            "tensor([[[0.9253, 0.6216, 0.0870,  ..., 0.3235, 0.2182, 0.6038],\n",
            "         [0.5770, 0.4125, 0.4155,  ..., 0.8245, 0.2182, 0.7172],\n",
            "         [0.3053, 0.3932, 0.8221,  ..., 0.9512, 0.5634, 0.1133],\n",
            "         ...,\n",
            "         [0.9302, 0.3663, 0.3147,  ..., 0.6456, 0.7483, 0.9207],\n",
            "         [0.0365, 0.1933, 0.2288,  ..., 0.8426, 0.5965, 0.2072],\n",
            "         [0.1383, 0.8602, 0.2365,  ..., 0.9532, 0.4748, 0.1956]],\n",
            "\n",
            "        [[0.4505, 0.9730, 0.7374,  ..., 0.5542, 0.2132, 0.1775],\n",
            "         [0.1799, 0.3353, 0.1107,  ..., 0.0491, 0.4735, 0.5556],\n",
            "         [0.6333, 0.8485, 0.6545,  ..., 0.0937, 0.5422, 0.8172],\n",
            "         ...,\n",
            "         [0.1712, 0.8012, 0.5905,  ..., 0.5038, 0.7268, 0.8026],\n",
            "         [0.7392, 0.7709, 0.9919,  ..., 0.4395, 0.0918, 0.7806],\n",
            "         [0.6970, 0.6940, 0.3232,  ..., 0.0278, 0.1551, 0.2573]],\n",
            "\n",
            "        [[0.6463, 0.3170, 0.8572,  ..., 0.6550, 0.9942, 0.7192],\n",
            "         [0.4015, 0.8026, 0.3086,  ..., 0.1325, 0.1156, 0.4235],\n",
            "         [0.7804, 0.3418, 0.0932,  ..., 0.9529, 0.4055, 0.4319],\n",
            "         ...,\n",
            "         [0.9255, 0.9414, 0.2592,  ..., 0.3113, 0.4922, 0.4213],\n",
            "         [0.6556, 0.6645, 0.8020,  ..., 0.5762, 0.3460, 0.7404],\n",
            "         [0.8914, 0.9490, 0.2904,  ..., 0.3514, 0.8974, 0.4775]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.0735, 0.0949, 0.9380,  ..., 0.1434, 0.2252, 0.0920],\n",
            "         [0.7783, 0.8101, 0.2888,  ..., 0.5048, 0.7180, 0.3545],\n",
            "         [0.8182, 0.4464, 0.3895,  ..., 0.0785, 0.9136, 0.0309],\n",
            "         ...,\n",
            "         [0.9103, 0.6788, 0.2530,  ..., 0.7500, 0.5905, 0.2547],\n",
            "         [0.1634, 0.2513, 0.6296,  ..., 0.1820, 0.5529, 0.2445],\n",
            "         [0.9801, 0.2009, 0.3868,  ..., 0.6447, 0.0807, 0.8366]],\n",
            "\n",
            "        [[0.6634, 0.2280, 0.8840,  ..., 0.6725, 0.8884, 0.9971],\n",
            "         [0.0773, 0.9635, 0.6534,  ..., 0.0165, 0.6925, 0.0545],\n",
            "         [0.6147, 0.2749, 0.7817,  ..., 0.9737, 0.3216, 0.3549],\n",
            "         ...,\n",
            "         [0.5902, 0.7472, 0.7794,  ..., 0.4913, 0.1206, 0.3382],\n",
            "         [0.0640, 0.5229, 0.5187,  ..., 0.3732, 0.4232, 0.3854],\n",
            "         [0.5774, 0.7476, 0.6126,  ..., 0.5576, 0.8963, 0.5585]],\n",
            "\n",
            "        [[0.2983, 0.3764, 0.4866,  ..., 0.4216, 0.8898, 0.0520],\n",
            "         [0.6284, 0.6736, 0.7385,  ..., 0.0924, 0.7393, 0.5015],\n",
            "         [0.3358, 0.4864, 0.2042,  ..., 0.0024, 0.4589, 0.3486],\n",
            "         ...,\n",
            "         [0.0560, 0.2154, 0.9792,  ..., 0.0188, 0.1475, 0.6723],\n",
            "         [0.3836, 0.4069, 0.3868,  ..., 0.2326, 0.2445, 0.6958],\n",
            "         [0.6568, 0.9565, 0.7665,  ..., 0.4823, 0.3116, 0.0102]]])\n",
            "tensor([[[4.6340, 5.3038, 4.6868,  ..., 5.0109, 4.6725, 5.4209],\n",
            "         [5.6594, 5.3667, 4.8400,  ..., 5.3022, 4.9646, 6.1084],\n",
            "         [5.5793, 5.4696, 5.4433,  ..., 5.9355, 5.5685, 6.7787],\n",
            "         ...,\n",
            "         [4.2834, 4.5911, 4.4706,  ..., 4.5181, 4.5788, 4.9602],\n",
            "         [4.1003, 3.5187, 3.7705,  ..., 3.6067, 4.0244, 3.7856],\n",
            "         [4.7821, 4.5399, 4.1019,  ..., 4.8941, 4.3987, 5.3324]],\n",
            "\n",
            "        [[3.8271, 5.0063, 4.8317,  ..., 4.3210, 3.5765, 3.5816],\n",
            "         [2.8194, 4.2220, 4.4306,  ..., 3.5279, 3.3404, 2.9945],\n",
            "         [3.8164, 5.9187, 5.1405,  ..., 4.6213, 3.6989, 3.8747],\n",
            "         ...,\n",
            "         [4.7676, 6.2082, 5.8024,  ..., 5.7025, 4.7756, 5.0466],\n",
            "         [5.5012, 6.6900, 6.2374,  ..., 5.9885, 5.1171, 5.7250],\n",
            "         [3.6377, 4.8261, 3.9675,  ..., 3.9343, 3.3829, 3.1251]],\n",
            "\n",
            "        [[5.4617, 5.5319, 5.8161,  ..., 6.6414, 6.1736, 6.9215],\n",
            "         [5.3039, 3.7969, 4.8780,  ..., 4.6850, 4.6081, 5.5724],\n",
            "         [5.1682, 4.3693, 4.0935,  ..., 5.6021, 4.2245, 4.6266],\n",
            "         ...,\n",
            "         [5.6586, 4.6677, 4.5516,  ..., 5.9743, 4.9410, 5.6952],\n",
            "         [4.4039, 3.8894, 4.3971,  ..., 5.8745, 4.9511, 5.0474],\n",
            "         [5.1438, 5.0050, 4.9786,  ..., 6.6935, 5.0290, 6.1248]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[5.0720, 4.3162, 2.9655,  ..., 4.8491, 4.2223, 3.3464],\n",
            "         [4.9276, 5.4313, 4.8389,  ..., 6.0647, 5.7552, 4.4978],\n",
            "         [5.1591, 4.9941, 3.5364,  ..., 5.5869, 4.9958, 4.4222],\n",
            "         ...,\n",
            "         [6.0905, 5.3885, 4.7762,  ..., 6.7244, 6.7195, 5.8191],\n",
            "         [5.4683, 4.7448, 3.9167,  ..., 5.6083, 4.7634, 3.7317],\n",
            "         [6.7741, 6.2660, 4.6091,  ..., 6.2624, 6.3064, 5.1391]],\n",
            "\n",
            "        [[4.3610, 4.9970, 5.4652,  ..., 5.4246, 4.6294, 5.4064],\n",
            "         [3.7368, 3.4390, 4.5885,  ..., 5.3971, 3.1356, 5.1903],\n",
            "         [3.7167, 3.3354, 4.7180,  ..., 5.3300, 4.4967, 5.3725],\n",
            "         ...,\n",
            "         [3.7085, 3.1467, 5.0306,  ..., 4.8381, 4.2017, 5.6987],\n",
            "         [3.5930, 3.4162, 4.5714,  ..., 5.4694, 3.8573, 5.1214],\n",
            "         [3.6433, 4.1272, 5.2407,  ..., 5.3966, 4.4231, 5.9241]],\n",
            "\n",
            "        [[5.2206, 3.9377, 4.8683,  ..., 3.7134, 3.8756, 4.8290],\n",
            "         [6.9976, 4.9807, 6.1118,  ..., 4.8338, 4.3712, 5.0187],\n",
            "         [5.7114, 4.2276, 5.0040,  ..., 4.0804, 3.7389, 4.5614],\n",
            "         ...,\n",
            "         [5.3776, 4.3665, 4.9391,  ..., 3.0774, 4.5674, 5.0702],\n",
            "         [5.9457, 4.8496, 5.3848,  ..., 4.6008, 4.3176, 4.4332],\n",
            "         [6.9077, 5.0915, 5.4848,  ..., 4.9626, 4.7635, 5.5027]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ejemplo de broadcasting\n",
        "x1 = torch.rand((5,5))\n",
        "x2 = torch.rand((1,5))\n",
        "\n",
        "#matematicamente no tiene sentido restar una matriz menos un vector, pero si en pytorch\n",
        "#porque expanden el vector para que calkse con las filas de x1, y a eso se refiere\n",
        "#el termino broadcasting\n",
        "z = x1-x2\n",
        "print(z)\n",
        "\n",
        "z = x1 ** x2\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dj6UZBuY-Rl",
        "outputId": "0a151f3c-2912-428e-cbf4-46d51d6d4242"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4706,  0.1105,  0.0723,  0.5817, -0.1750],\n",
            "        [-0.2056,  0.7370,  0.0266, -0.3236,  0.2855],\n",
            "        [-0.1076,  0.4572,  0.2746, -0.3530, -0.1681],\n",
            "        [-0.2850,  0.6291, -0.2891,  0.4056,  0.6099],\n",
            "        [ 0.5067,  0.1692, -0.0600,  0.3829,  0.6298]])\n",
            "tensor([[0.9764, 0.8278, 0.7470, 0.9868, 0.5000],\n",
            "        [0.5378, 0.9817, 0.7168, 0.3406, 0.8619],\n",
            "        [0.6226, 0.9319, 0.8658, 0.2639, 0.5176],\n",
            "        [0.4566, 0.9644, 0.4406, 0.9134, 0.9594],\n",
            "        [0.9940, 0.8520, 0.6550, 0.9032, 0.9644]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#otras operaciones utiles\n",
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([9,8,7])\n",
        "#suma de los elementos\n",
        "sum_x = torch.sum(x, dim=0) # 0 xq es 1 vector\n",
        "print(sum_x)\n",
        "values, indices = torch.max(x, dim=0 )\n",
        "print(values, indices)\n",
        "values, indices = torch.min(x, dim=0 )\n",
        "print(values, indices)\n",
        "abs_x = torch.abs(x) #valor absoluto\n",
        "print(abs_x)\n",
        "z = torch.argmax(x, dim=0) #lo mismo que torch.max pero solo retorna el indice\n",
        "print(z)\n",
        "z = torch.argmin(x, dim=0) #lo mismo que torch.minx pero solo retorna el indice\n",
        "print(z)\n",
        "mean_x = torch.mean(x.float(), dim = 0) #requiere que sea float\n",
        "print(mean_x)\n",
        "#comparar si 2 elementos son iguales\n",
        "z = torch.eq(x,y)\n",
        "print(z)\n",
        "\n",
        "#sort\n",
        "sorted_y, indices = torch.sort(y, dim = 0, descending = False) # retorna sorted y el indice de posicion anterior\n",
        "print(sorted_y, indices)\n",
        "\n",
        "#compara todos los elementos menores que cero y los vuelve cero y sobre 10 los convierte a 10, pero el argumento max no es necesario\n",
        "z = torch.clamp(x, min = 0, max=10 )\n",
        "print(z)\n",
        "\n",
        "x = torch.tensor([1,0,1,1,1], dtype = torch.bool)\n",
        "print(x)\n",
        "z = torch.any(x) #si al menos 1 es true retorna true\n",
        "print(z)\n",
        "z = torch.all(x) #si todo true retorna true, sino false\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcm67yNjbdhc",
        "outputId": "82fe006f-97cc-4f83-8fdd-4b219f2c61af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6)\n",
            "tensor(3) tensor(2)\n",
            "tensor(1) tensor(0)\n",
            "tensor([1, 2, 3])\n",
            "tensor(2)\n",
            "tensor(0)\n",
            "tensor(2.)\n",
            "tensor([False, False, False])\n",
            "tensor([7, 8, 9]) tensor([2, 1, 0])\n",
            "tensor([1, 2, 3])\n",
            "tensor([ True, False,  True,  True,  True])\n",
            "tensor(True)\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indices de tensores\n",
        "batch_size = 10\n",
        "features = 25\n",
        "x = torch.rand((batch_size, features))\n",
        "\n",
        "print(x[0].shape) # lo mismo que x[0,:]\n",
        "\n",
        "print(x[:,0].shape)\n",
        "print(x[2,0:10])\n",
        "x[0,0] = 100\n",
        "\n",
        "x =torch.arange(10)\n",
        "indices = [2,5,8]\n",
        "print(x[indices])\n",
        "\n",
        "x = torch.rand((3,5))\n",
        "\n",
        "rows = torch.tensor([1,0])\n",
        "cols = torch.tensor([4,0])\n",
        "print(x)\n",
        "print(x[rows, cols])\n",
        "\n",
        "#indexacion mas avanzada\n",
        "x = torch.arange(10)\n",
        "print(x)\n",
        "print(x[(x < 2) | (x > 8)])\n",
        "print(x[x.remainder(2) == 0]) #modulo 2 == 0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWkfO1Laf64r",
        "outputId": "e40be294-bf80-4ca9-b9a8-2bd15513e3f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25])\n",
            "torch.Size([10])\n",
            "tensor([0.3164, 0.3998, 0.7438, 0.5359, 0.6174, 0.5521, 0.6333, 0.5623, 0.3949,\n",
            "        0.3723])\n",
            "tensor([2, 5, 8])\n",
            "tensor([[0.4321, 0.0791, 0.1008, 0.8981, 0.7324],\n",
            "        [0.1863, 0.5856, 0.0690, 0.3647, 0.4594],\n",
            "        [0.9666, 0.6111, 0.1921, 0.3804, 0.4444]])\n",
            "tensor([0.4594, 0.4321])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([0, 1, 9])\n",
            "tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#operaciones utiles\n",
        "\n",
        "print(torch.where(x > 5, x, x*2)) # si el valor es > 5 retorno el valor, sino el valor x2\n",
        "print(torch.tensor([0,0,1,1,2,2,3,4]).unique()) #elementos unicos\n",
        "x = torch.arange(10)\n",
        "print(x.ndimension()) #1 sola dimension\n",
        "print(x.numel()) #numero de elementos en x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS_fPZiejliq",
        "outputId": "f0e5d29f-8c3b-41cc-ddd0-7c16bb861511"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
            "tensor([0, 1, 2, 3, 4])\n",
            "1\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remodelar (reshape)\n",
        "x = torch.arange(9) #lo convertiremos en 3x3\n",
        "print(x)\n",
        "x_3x3 = x.view(3,3)\n",
        "print(x_3x3)\n",
        "x_3x3 = x.reshape(3,3)\n",
        "print(x_3x3)\n",
        "#view y reshape son similares, view trabaja con tensores contiguos en memoria, reshape no importa xcq hara una copia\n",
        "#por eso reshape es mas seguro, porque puede tirar errores a veces cuando se hacen mas operaciones como\n",
        "#trasponer y luego hacer view(9)\n",
        "\n",
        "#y = x_3x3.t()\n",
        "#print(y)\n",
        "#print(y.view(9))\n",
        "#RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
        "x1 = torch.rand((2,5))\n",
        "x2 = torch.rand((2,5))\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(torch.cat((x1,x2), dim=0).shape) #cat de concatenar\n",
        "print(torch.cat((x1,x2), dim=1).shape) #cat de concatenar\n",
        "\n",
        "z = x1.view(-1) #esto es magia xD sirve para aplanar (flatten) el tensor\n",
        "print(x1)\n",
        "print(z)\n",
        "\n",
        "batch = 64\n",
        "x = torch.rand((batch, 2, 5,5))\n",
        "print(x.shape)\n",
        "z = x.view(batch,-1)\n",
        "print(z.shape)\n",
        "\n",
        "x = torch.arange(10)\n",
        "print(x.unsqueeze(0)) #Returns a new tensor with a dimension of size one inserted at the specified position\n",
        "print(x.unsqueeze(1))\n",
        "\n",
        "x = torch.arange(10).unsqueeze(0).unsqueeze(1) #1xx1x10\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCq7G4xIkTHa",
        "outputId": "9fd6a50c-5ab3-4191-c16d-db1a0edbf040"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0.1443, 0.8832, 0.9177, 0.1913, 0.2832],\n",
            "        [0.4397, 0.6387, 0.5466, 0.8864, 0.8141]])\n",
            "tensor([[0.3929, 0.0498, 0.4543, 0.1167, 0.4053],\n",
            "        [0.9646, 0.4426, 0.6723, 0.0685, 0.4420]])\n",
            "torch.Size([4, 5])\n",
            "torch.Size([2, 10])\n",
            "tensor([[0.1443, 0.8832, 0.9177, 0.1913, 0.2832],\n",
            "        [0.4397, 0.6387, 0.5466, 0.8864, 0.8141]])\n",
            "tensor([0.1443, 0.8832, 0.9177, 0.1913, 0.2832, 0.4397, 0.6387, 0.5466, 0.8864,\n",
            "        0.8141])\n",
            "torch.Size([64, 2, 5, 5])\n",
            "torch.Size([64, 50])\n",
            "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8],\n",
            "        [9]])\n",
            "tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gradientes (copiado de https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)\n",
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "print(w)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "print(b)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "print(y,z, loss)\n",
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y892FAC1BOZQ",
        "outputId": "90bb43d5-ec5b-4e84-cb86-15c2db298a8b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6518,  1.6231, -0.2330],\n",
            "        [-0.6221,  0.3071, -0.4295],\n",
            "        [ 0.3938, -1.5712,  1.6169],\n",
            "        [ 1.7591, -0.5017, -1.1352],\n",
            "        [ 0.7453, -0.3873,  1.0562]], requires_grad=True)\n",
            "tensor([ 0.6038,  2.4329, -0.9644], requires_grad=True)\n",
            "tensor([0., 0., 0.]) tensor([ 2.2281,  1.9029, -0.0888], grad_fn=<AddBackward0>) tensor(1.6740, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Gradient function for z = <AddBackward0 object at 0x7bce74a04190>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7bcd9970a2f0>\n",
            "tensor([[0.3009, 0.2901, 0.1593],\n",
            "        [0.3009, 0.2901, 0.1593],\n",
            "        [0.3009, 0.2901, 0.1593],\n",
            "        [0.3009, 0.2901, 0.1593],\n",
            "        [0.3009, 0.2901, 0.1593]])\n",
            "tensor([0.3009, 0.2901, 0.1593])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Disabling Gradient Tracking\n",
        "#By default, all tensors with requires_grad=True are tracking their computational history and support gradient computation. However, there are some cases when we do not need to do that, for example,\n",
        "#when we have trained the model and just want to apply it to some input data, i.e. we only want to do forward computations through the network. We can stop tracking computations by surrounding our\n",
        "#computation code with torch.no_grad() block:\n",
        "\n",
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA89G8FxCTan",
        "outputId": "3e5a6ae5-3be7-46bb-c48d-774d378e58d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    }
  ]
}